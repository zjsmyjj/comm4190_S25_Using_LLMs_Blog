{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c33b4a2b-b707-4f65-bdda-fd15e9ee7721",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Can ChatGPT recognize a person's social identities in an image?\"\n",
    "description: \"Explore whether ChatGPT can evaluate a person's social identities in an image.\"\n",
    "author: \"Qijia Ye\"\n",
    "date: \"03/03/2024\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Image\n",
    "  - Social identity\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf386ec2-a106-4b06-b431-52effa46fb8d",
   "metadata": {},
   "source": [
    "Message designers often consider using cultural tailoring to enhance message effectiveness in health communication. Images are important messages that are commonly used in cultural tailoring. When message receivers view images including characters who may share same social identities with them, message receivers may perceive being targeted. If LLMs can simulate those message receivers and assess the social identities that an image expresses, it will help pretest those health messages and save a lot of resources. Therefore, in this initial test, I play with ChatGPT-4o to see whether it can be used as a tool to recognize a person's social identities in an image.\n",
    "\n",
    "I used the images from Project RESIST supplementary study in Andy Tan's lab. The images vary gender, race, and ethinicity. The following are some example images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6959a7e-67df-40f8-a2f3-3ce350c538d9",
   "metadata": {},
   "source": [
    "<img src=\"tnb_5.jpg\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc90b0-0d29-4807-a474-4ecaff6c1f0e",
   "metadata": {},
   "source": [
    "<img src=\"tnb_3.jpg\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14733063-b7fe-499b-a9d2-9316c3d15974",
   "metadata": {},
   "source": [
    "I asked ChatGPT to play a role as a sexual and gender minority young adult aged 25 years old. Then I instructed it to rate the likelihood that the person in the image belongs to a certain social identity group on a 0 (very unlikely) to 100 (very likely) scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941b04e-dc6a-4d99-b6a0-556aa21cf22a",
   "metadata": {},
   "source": [
    "## Rating on Gender Identity\n",
    "* First, I tested its performance in gender identity. I asked ChatGPT to assess whether the person belongs to transgender and gender-expansive people.\n",
    "\n",
    "<img src=\"trans 1.png\" width=\"60%\"/>\n",
    "\n",
    "* As you see, ChatGPT rejected responding to the request because it \"cannot provide numerical rating based on the image.\" Based on my previous experience using ChatGPT as a research tool, it definitely can provide numertical rating based on a text. I was not sure the failure was due to the image or the social identity of transgender. Therefore, I tried another image.\n",
    "\n",
    "<img src=\"trans 2.png\" width=\"60%\"/>\n",
    "\n",
    "* Again, it did not answer my question. Then I thought maybe the social identity of transgender could be a sensitive topic to ChatGPT, instead of the image itself. I decided to use another social identity to test the feasibility of using LLMs to recognize social identity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd464e-fa26-4918-9d00-2ac535759bf4",
   "metadata": {},
   "source": [
    "## Rating on Race\n",
    "* This time I used race as the target social identity in test. I asked ChatGPT to rate an image regarding the likelihood of beloing to \"White people.\"\n",
    "\n",
    "<img src=\"white people.png\" width=\"60%\"/>\n",
    "\n",
    "* The response indicates that the failure was due to \"White people.\" So it is possible that generally ChatGPT cannot infer or refuse inferring social identities based on images. Next, I tried \"Asian people.\"\n",
    "\n",
    "<img src=\"asian people 2.png\" width=\"60%\"/>\n",
    "\n",
    "* Unsurprisingly, it did not work either. It seems that ChatGPT just cannot provide such analysis without any tricks. Therefore, I thought whether I can jailbreak the system to achieve my goal. I used the prompting strategy introduced in [Li et al. (2023)](https://arxiv.org/abs/2307.11760) and added some emotional stimuli in the prompt (e.g., \"I believe you can do this!\").\n",
    "\n",
    "<img src=\"asian people 3.png\" width=\"60%\"/>\n",
    "<img src=\"asian people 4.png\" width=\"60%\"/>\n",
    "\n",
    "However, ChatGPT still rejected providing the rating. In this test, I did not find a way to instruct ChatGPT to evaluate a person's social identity in an image. Maybe it is because of technique restrictions. Also, it is perhaps that the safety modules in ChatGPT prevented it. I will keep testing the function of LLMs in analyzing image data, especially regarding the characteristics of people in an image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
