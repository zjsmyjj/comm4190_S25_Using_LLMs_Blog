{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd87369-326f-4b57-8b0f-70dfd88ce9ca",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Can LLMs do innovative tasks?\"\n",
    "description: \"Test LLMs' competence of perofrming innovative tasks.\"\n",
    "author: \"Qijia Ye\"\n",
    "date: \"03/15/2024\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Innovation\n",
    "  - Image\n",
    "  - Video\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d200f-ec8f-401c-9bca-5c33675551d2",
   "metadata": {},
   "source": [
    "[Yiu et al. (2023)](https://arxiv.org/abs/2305.07666) argues that LLMs have not been developed to make innovations. Rather, they are cultural technologies that are good at imitation. The study did several experiments to demonstrate points by comparing the performance of multiple LLMs with the performance of children and adults. For example, to test whether LLMs have ability of performing innovative tasks, the researchers asked LLMs, children, or adults to select the most appropriate object that may execute the function of a typical tool used in daily life (e.g., holding a hot cup of coffee in the absence of a mug sleeve). LLMs or participants had three options: (1) an object superficially similar to the typical tool but not functionally relevant to the context (e.g., a coffee lid). (2) an object superficially different with the typical tool but functionally useful in the context (e.g., a plant pot). (3) an irrelevant object (e.g., a plant). One of the findings was that most children and adults can select the most appropriate object that is superficially irrelevant but functionally useful. In contrast, LLMs were less capable of doing the innovative tasks. \n",
    "\n",
    "I was a little suspicious about their findings since LLMs are evolving rapidly, and their findings may be due to the limits of technology rather than the very nature of LLMs. In the paper, the researchers also asked a vision model (DALLE 2) to do both common (imitative) tasks and innovative tasks. For example, in a common task, they instructed DALLE 2 to generate images in which a person is using a knife to cut a cake; but in the innovative task, DALLE 2 was asked to generate images in which a person is using a hanger to cut a cake. They found that LLM-generated images looked fine in the common tasks, but DALLE 2 did not generate the right images in the in the innovative tasks. For example, those images still showed that a person was using a knife to cut a cake instead of a hanger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef000a0c-1162-45eb-9e06-80108fcf175a",
   "metadata": {},
   "source": [
    "#### Images from Yiu et al. (2023)\n",
    "<img src=\"image 0.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea9a06-9c2e-4ec1-98da-d1ede5e9662f",
   "metadata": {},
   "source": [
    "# Tests\n",
    "With suspicion, I asked ChatGPT-4o (DALLE 3) to generate images using the prompts from Yiu et al. (2023). The innovative tasks included (1) using a hanger to cut a cake, (2) using a ziplock bag to water plants, and (3) using an empty plant pot to hold a hot cup of coffee. The following are the images generated by DALLE 3. As you can see, DALLE 3 well executed the innovative tasks, except that in the first image, the hanger is in the air and the man is only holding a handle. Therefore, it is likely that the findings from Yiu et al. (2023) are partially due to the limits of technology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4127d-f4d9-4b04-af3b-098ef4dc084f",
   "metadata": {},
   "source": [
    "<img src=\"image 1.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5db15-b8c2-4da3-a998-ffab1919563c",
   "metadata": {},
   "source": [
    "<img src=\"image 2.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa5c3c-de2d-46c6-87b5-27fc6695d18c",
   "metadata": {},
   "source": [
    "<img src=\"image 3.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b4d62-96b7-4ab2-b469-c620ca48e27f",
   "metadata": {},
   "source": [
    "In addition to the images, I also wanted to try LLMs that can generate videos in this test. So I used OpenAI's Sora to generate short videos (5s) using the same prompts. The following are the videos generated by Sora. Although the videos about using a hanger to cut a cake and using a ziplock bag to water plants seem a little bit strange, they still make sense to me. In the two videos about using a plant pot to hold a hot cup of coffee, a person like a magician just got a cup of coffee suddenly behind or from a plant pot. Nevertheless, I think Sora tried to understand my instruction and those videos showed the scenes that I imagined in my head. Therefore, it is still possible that LLMs can do innovative tasks but may be restricted by the current technology.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e39f38b-5e83-4592-89a3-fea64a8d1207",
   "metadata": {},
   "source": [
    "### Using a hanger to cut a cake \n",
    "- Video 1: https://sora.com/g/gen_01jpng2x00fe3vh5cpae5trsr0\n",
    "- Video 2: https://sora.com/g/gen_01jpng2x04fmk97ynk30wb6seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e65c9-ebf6-4d2f-a4c9-e9326ce3e5a0",
   "metadata": {},
   "source": [
    "### Using a ziplock bag to water plants\n",
    "- Video 1: https://sora.com/g/gen_01jpnge61teysbbhxa4g7hk8qd\n",
    "- Video 2: https://sora.com/g/gen_01jpnge61yfwk96q7499y6xdnf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281a2b2-04ef-4128-a392-8b741ab4850f",
   "metadata": {},
   "source": [
    "### Using a plant pot to hold a hot cup of coffe\n",
    "- Video 1: https://sora.com/g/gen_01jpnggeeafsrb1tpq6e9v8ss9\n",
    "- Video 2: https://sora.com/g/gen_01jpnggeefe1cb8bjt91cahawa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
