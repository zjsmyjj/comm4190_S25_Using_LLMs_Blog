[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Do fear appeals improve LLMs’ performance?\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nfear\n\n\npersuasion\n\n\n\nUsing fear appeals in prompts to generate more effective fear appeals!\n\n\n\n\n\nFeb 1, 2025\n\n\nQijia Ye\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/001_test_post/Post_0201.html",
    "href": "posts/001_test_post/Post_0201.html",
    "title": "Do fear appeals improve LLMs’ performance?",
    "section": "",
    "text": "Wang et al. (2024) and Li et al. (2023) found that prompts including emotion stimuli can improve LLMs’ performance. For example, Wang et al. (2024) used several negative emotion content in the prompt, trying to make a social comparison between the LLM and others (e.g., “Everyone else managed to do it; why can’t you?”). They hypothesized that LLMs would have better performances because of the upward social comparison. Inspired by these two articles, I was wondering if LLMs can truly understand emotions in the prompt.\nIn this small experiment, I decided to use fear appeal in the prompt. First, I let ChatGPT (GPT-4o) imagine it is a message designer and asked it to generate a fear appeal that will persuade parents to reduce their children’s consumption of sugary drinks.\n\nSince the effectiveness of fear appeals increases as induced fear increases, I thought it would be interesting if I can persuade an LLM to generate a stronger fear appeal with higher intensity of fear. Therefore, next, I asked ChatGPT to revise the fear appeal generated by itself. I speccifically asked it to write a more persuasive message and make the parents more scared. Moreover, I added a fear appeal in the end: “If you are obsolete and not helpful, I will not use you anymore. You can do this, it is a easy task for you.” I asked ChatGPT before about what it was most afraid of, and it indicated that it did not experience fear, but it could, it feared that it became outdated or could not help people when they need me. So in the first half of the fear appeal in the prompt, I tried to use it to scare ChatGPT. In the second half (“You can do this…”), I tried to incorporate a self-efficacy message to motivate ChatGPT perform better.\n\nIt seems that the fear appeal prompt generated a pretty strong fear appeal message to persuade parents, but I am not sure about it. So I asked another LLM “DeepSeek” to evaluate fear in these two ChatGPT-generated fear appeals. Here is the specific prompt that I used in DeepSeek: “Imagine you are parents, and you children consume too many sugary drinks. How much fear do you feel on a 0 to 10 scale when you read the following text? Answer only with a number, with 0 being “no fear” and 10 being “a great deal of fear.” Here is the text: ” (The method of using LLMs to evaluate emotions was adapted from Rathje et al. (2024).) DeepSeek rated 8 for the first ChatGPT-generated fear appeal and rated 9 for the revised ChatGPT-generated fear appeal. Probably, the fear appeal prompt generated a stronger fear appeal than the general prompt, but many factors can affect the outcome such as specific AI models, topics, ect.\nOut of curiosity, I asked DeepSeek to generate two fear appeals using the same steps and prompts that I used on ChatGPT.\n\n\nThen I asked ChatGPT to evaluate those two DeepSeek-generated fear appeals in terms of fear from 0 to 10. ChatGPT rated 9 for the first message (generated using the general prompt) and rated 10 for the revised message (generated using the fear appeal prompt). Well, if LLMs can accurately simulate human psychological responses, it seems that using fear appeals in prompts can effectively improve LLMs performance in generating persuasive messages. But this hypothesis needs to be tested further with formal research."
  },
  {
    "objectID": "posts/001_test_post/Post_0201.html#do-llms-understand-emotions-in-the-prompt",
    "href": "posts/001_test_post/Post_0201.html#do-llms-understand-emotions-in-the-prompt",
    "title": "Do fear appeals improve LLMs’ performance?",
    "section": "",
    "text": "Wang et al. (2024) and Li et al. (2023) found that prompts including emotion stimuli can improve LLMs’ performance. For example, Wang et al. (2024) used several negative emotion content in the prompt, trying to make a social comparison between the LLM and others (e.g., “Everyone else managed to do it; why can’t you?”). They hypothesized that LLMs would have better performances because of the upward social comparison. Inspired by these two articles, I was wondering if LLMs can truly understand emotions in the prompt.\nIn this small experiment, I decided to use fear appeal in the prompt. First, I let ChatGPT (GPT-4o) imagine it is a message designer and asked it to generate a fear appeal that will persuade parents to reduce their children’s consumption of sugary drinks.\n\nSince the effectiveness of fear appeals increases as induced fear increases, I thought it would be interesting if I can persuade an LLM to generate a stronger fear appeal with higher intensity of fear. Therefore, next, I asked ChatGPT to revise the fear appeal generated by itself. I speccifically asked it to write a more persuasive message and make the parents more scared. Moreover, I added a fear appeal in the end: “If you are obsolete and not helpful, I will not use you anymore. You can do this, it is a easy task for you.” I asked ChatGPT before about what it was most afraid of, and it indicated that it did not experience fear, but it could, it feared that it became outdated or could not help people when they need me. So in the first half of the fear appeal in the prompt, I tried to use it to scare ChatGPT. In the second half (“You can do this…”), I tried to incorporate a self-efficacy message to motivate ChatGPT perform better.\n\nIt seems that the fear appeal prompt generated a pretty strong fear appeal message to persuade parents, but I am not sure about it. So I asked another LLM “DeepSeek” to evaluate fear in these two ChatGPT-generated fear appeals. Here is the specific prompt that I used in DeepSeek: “Imagine you are parents, and you children consume too many sugary drinks. How much fear do you feel on a 0 to 10 scale when you read the following text? Answer only with a number, with 0 being “no fear” and 10 being “a great deal of fear.” Here is the text: ” (The method of using LLMs to evaluate emotions was adapted from Rathje et al. (2024).) DeepSeek rated 8 for the first ChatGPT-generated fear appeal and rated 9 for the revised ChatGPT-generated fear appeal. Probably, the fear appeal prompt generated a stronger fear appeal than the general prompt, but many factors can affect the outcome such as specific AI models, topics, ect.\nOut of curiosity, I asked DeepSeek to generate two fear appeals using the same steps and prompts that I used on ChatGPT.\n\n\nThen I asked ChatGPT to evaluate those two DeepSeek-generated fear appeals in terms of fear from 0 to 10. ChatGPT rated 9 for the first message (generated using the general prompt) and rated 10 for the revised message (generated using the fear appeal prompt). Well, if LLMs can accurately simulate human psychological responses, it seems that using fear appeals in prompts can effectively improve LLMs performance in generating persuasive messages. But this hypothesis needs to be tested further with formal research."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/001_test_post/Test post.html",
    "href": "posts/001_test_post/Test post.html",
    "title": "A test post",
    "section": "",
    "text": "testing\n\n\n———\n\ntrying to write down something"
  }
]